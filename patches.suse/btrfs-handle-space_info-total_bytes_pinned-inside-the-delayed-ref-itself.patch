From: Josef Bacik <josef@toxicpanda.com>
Date: Fri, 15 Jan 2021 16:48:55 -0500
Subject: btrfs: handle space_info::total_bytes_pinned inside the delayed ref
 itself
Git-commit: 2187374f35fe9cadbddaa9fcf0c4121365d914e8
Patch-mainline: v5.12-rc1
References: bsc#1135481

Currently we pass things around to figure out if we maybe freeing data
based on the state of the delayed refs head.  This makes the accounting
sort of confusing and hard to follow, as it's distinctly separate from
the delayed ref heads stuff, but also depends on it entirely.

Fix this by explicitly adjusting the space_info->total_bytes_pinned in
the delayed refs code.  We now have two places where we modify this
counter, once where we create the delayed and destroy the delayed refs,
and once when we pin and unpin the extents.  This means there is a
slight overlap between delayed refs and the pin/unpin mechanisms, but
this is simply used by the ENOSPC infrastructure to determine if we need
to commit the transaction, so there's no adverse affect from this, we
might simply commit thinking it will give us enough space when it might
not.

CC: stable@vger.kernel.org # 5.10
Reviewed-by: Nikolay Borisov <nborisov@suse.com>
Signed-off-by: Josef Bacik <josef@toxicpanda.com>
Signed-off-by: David Sterba <dsterba@suse.com>
Acked-by: Nikolay Borisov <nborisov@suse.com>
---
 fs/btrfs/block-group.c |    9 +----
 fs/btrfs/delayed-ref.c |   54 +++++++++++++++++--------------
 fs/btrfs/delayed-ref.h |   16 +++++++--
 fs/btrfs/extent-tree.c |   84 ++++++++-----------------------------------------
 fs/btrfs/space-info.h  |   17 +++++++++
 5 files changed, 77 insertions(+), 103 deletions(-)

--- a/fs/btrfs/block-group.c
+++ b/fs/btrfs/block-group.c
@@ -1357,9 +1357,7 @@ void btrfs_delete_unused_bgs(struct btrf
 		btrfs_space_info_update_bytes_pinned(fs_info, space_info,
 						     -block_group->pinned);
 		space_info->bytes_readonly += block_group->pinned;
-		percpu_counter_add_batch(&space_info->total_bytes_pinned,
-				   -block_group->pinned,
-				   BTRFS_TOTAL_BYTES_PINNED_BATCH);
+		__btrfs_mod_total_bytes_pinned(space_info, -block_group->pinned);
 		block_group->pinned = 0;

 		spin_unlock(&block_group->lock);
@@ -2714,9 +2712,8 @@ int btrfs_update_block_group(struct btrf
 			spin_unlock(&cache->lock);
 			spin_unlock(&cache->space_info->lock);

-			percpu_counter_add_batch(&cache->space_info->total_bytes_pinned,
-					   num_bytes,
-					   BTRFS_TOTAL_BYTES_PINNED_BATCH);
+			__btrfs_mod_total_bytes_pinned(cache->space_info,
+						       num_bytes);
 			set_extent_dirty(info->pinned_extents,
 					 bytenr, bytenr + num_bytes - 1,
 					 GFP_NOFS | __GFP_NOFAIL);
--- a/fs/btrfs/delayed-ref.c
+++ b/fs/btrfs/delayed-ref.c
@@ -655,12 +655,12 @@ inserted:
  */
 static noinline void update_existing_head_ref(struct btrfs_trans_handle *trans,
 			 struct btrfs_delayed_ref_head *existing,
-			 struct btrfs_delayed_ref_head *update,
-			 int *old_ref_mod_ret)
+			 struct btrfs_delayed_ref_head *update)
 {
 	struct btrfs_delayed_ref_root *delayed_refs =
 		&trans->transaction->delayed_refs;
 	struct btrfs_fs_info *fs_info = trans->fs_info;
+	u64 flags = btrfs_ref_head_to_space_flags(existing);
 	int old_ref_mod;

 	BUG_ON(existing->is_data != update->is_data);
@@ -708,8 +708,6 @@ static noinline void update_existing_hea
 	 * currently, for refs we just added we know we're a-ok.
 	 */
 	old_ref_mod = existing->total_ref_mod;
-	if (old_ref_mod_ret)
-		*old_ref_mod_ret = old_ref_mod;
 	existing->ref_mod += update->ref_mod;
 	existing->total_ref_mod += update->ref_mod;

@@ -731,6 +729,22 @@ static noinline void update_existing_hea
 			trans->delayed_ref_updates += csum_leaves;
 		}
 	}
+
+	/*
+	 * This handles the following conditions:
+	 *
+	 * 1. We had a ref mod of 0 or more and went negative, indicating that
+	 *    we may be freeing space, so add our space to the
+	 *    total_bytes_pinned counter.
+	 * 2. We were negative and went to 0 or positive, so no longer can say
+	 *    that the space would be pinned, decrement our counter from the
+	 *    total_bytes_pinned counter.
+	 */
+	if (existing->total_ref_mod < 0 && old_ref_mod >= 0)
+		btrfs_mod_total_bytes_pinned(fs_info, flags, existing->num_bytes);
+	else if (existing->total_ref_mod >= 0 && old_ref_mod < 0)
+		btrfs_mod_total_bytes_pinned(fs_info, flags, -existing->num_bytes);
+
 	spin_unlock(&existing->lock);
 }

@@ -807,9 +821,7 @@ add_delayed_ref_head(struct btrfs_fs_inf
 		     struct btrfs_trans_handle *trans,
 		     struct btrfs_delayed_ref_head *head_ref,
 		     struct btrfs_qgroup_extent_record *qrecord,
-		     int action, int *qrecord_inserted_ret,
-		     int *old_ref_mod, int *new_ref_mod)
-
+		     int action, int *qrecord_inserted_ret)
 {
 	struct btrfs_delayed_ref_head *existing;
 	struct btrfs_delayed_ref_root *delayed_refs;
@@ -831,8 +843,7 @@ add_delayed_ref_head(struct btrfs_fs_inf
 	existing = htree_insert(&delayed_refs->href_root,
 				&head_ref->href_node);
 	if (existing) {
-		update_existing_head_ref(trans, existing, head_ref,
-					 old_ref_mod);
+		update_existing_head_ref(trans, existing, head_ref);
 		/*
 		 * we've updated the existing ref, free the newly
 		 * allocated ref
@@ -840,14 +851,17 @@ add_delayed_ref_head(struct btrfs_fs_inf
 		kmem_cache_free(btrfs_delayed_ref_head_cachep, head_ref);
 		head_ref = existing;
 	} else {
-		if (old_ref_mod)
-			*old_ref_mod = 0;
+		u64 flags = btrfs_ref_head_to_space_flags(head_ref);
+
 		if (head_ref->is_data && head_ref->ref_mod < 0) {
 			delayed_refs->pending_csums += head_ref->num_bytes;
 			trans->delayed_ref_updates +=
 				btrfs_csum_bytes_to_leaves(trans->fs_info,
 							   head_ref->num_bytes);
 		}
+		if (head_ref->ref_mod < 0)
+			btrfs_mod_total_bytes_pinned(trans->fs_info, flags,
+						     head_ref->num_bytes);
 		delayed_refs->num_heads++;
 		delayed_refs->num_heads_ready++;
 		atomic_inc(&delayed_refs->num_entries);
@@ -855,8 +869,6 @@ add_delayed_ref_head(struct btrfs_fs_inf
 	}
 	if (qrecord_inserted_ret)
 		*qrecord_inserted_ret = qrecord_inserted;
-	if (new_ref_mod)
-		*new_ref_mod = head_ref->total_ref_mod;

 	return head_ref;
 }
@@ -920,8 +932,7 @@ static void init_delayed_ref_common(stru
 int btrfs_add_delayed_tree_ref(struct btrfs_fs_info *fs_info,
 			       struct btrfs_trans_handle *trans,
 			       struct btrfs_ref *generic_ref,
-			       struct btrfs_delayed_extent_op *extent_op,
-			       int *old_ref_mod, int *new_ref_mod)
+			       struct btrfs_delayed_extent_op *extent_op)
 {
 	struct btrfs_delayed_tree_ref *ref;
 	struct btrfs_delayed_ref_head *head_ref;
@@ -981,9 +992,7 @@ int btrfs_add_delayed_tree_ref(struct bt
 	 * the spin lock
 	 */
 	head_ref = add_delayed_ref_head(fs_info, trans, head_ref, record,
-					action, &qrecord_inserted,
-					old_ref_mod, new_ref_mod);
-
+					action, &qrecord_inserted);

 	ret = insert_delayed_ref(trans, delayed_refs, head_ref, &ref->node);
 	spin_unlock(&delayed_refs->lock);
@@ -1017,8 +1026,7 @@ free_ref:
  */
 int btrfs_add_delayed_data_ref(struct btrfs_fs_info *fs_info,
 			       struct btrfs_trans_handle *trans,
-			       struct btrfs_ref *generic_ref, u64 reserved,
-			       int *old_ref_mod, int *new_ref_mod)
+			       struct btrfs_ref *generic_ref, u64 reserved)
 {
 	struct btrfs_delayed_data_ref *ref;
 	struct btrfs_delayed_ref_head *head_ref;
@@ -1083,8 +1091,7 @@ int btrfs_add_delayed_data_ref(struct bt
 	 * the spin lock
 	 */
 	head_ref = add_delayed_ref_head(fs_info, trans, head_ref, record,
-					action, &qrecord_inserted,
-					old_ref_mod, new_ref_mod);
+					action, &qrecord_inserted);

 	ret = insert_delayed_ref(trans, delayed_refs, head_ref, &ref->node);
 	spin_unlock(&delayed_refs->lock);
@@ -1127,8 +1134,7 @@ int btrfs_add_delayed_extent_op(struct b
 	spin_lock(&delayed_refs->lock);

 	add_delayed_ref_head(fs_info, trans, head_ref, NULL,
-			     BTRFS_UPDATE_DELAYED_HEAD,
-			     NULL, NULL, NULL);
+			     BTRFS_UPDATE_DELAYED_HEAD, NULL);

 	spin_unlock(&delayed_refs->lock);

--- a/fs/btrfs/delayed-ref.h
+++ b/fs/btrfs/delayed-ref.h
@@ -338,6 +338,16 @@ static inline void btrfs_put_delayed_ref
 	}
 }

+static inline u64 btrfs_ref_head_to_space_flags(
+				struct btrfs_delayed_ref_head *head_ref)
+{
+	if (head_ref->is_data)
+		return BTRFS_BLOCK_GROUP_DATA;
+	else if (head_ref->is_system)
+		return BTRFS_BLOCK_GROUP_SYSTEM;
+	return BTRFS_BLOCK_GROUP_METADATA;
+}
+
 static inline void btrfs_put_delayed_ref_head(struct btrfs_delayed_ref_head *head)
 {
 	if (refcount_dec_and_test(&head->refs))
@@ -347,12 +357,10 @@ static inline void btrfs_put_delayed_ref
 int btrfs_add_delayed_tree_ref(struct btrfs_fs_info *fs_info,
 			       struct btrfs_trans_handle *trans,
 			       struct btrfs_ref *generic_ref,
-			       struct btrfs_delayed_extent_op *extent_op,
-			       int *old_ref_mod, int *new_ref_mod);
+			       struct btrfs_delayed_extent_op *extent_op);
 int btrfs_add_delayed_data_ref(struct btrfs_fs_info *fs_info,
 			       struct btrfs_trans_handle *trans,
-			       struct btrfs_ref *generic_ref, u64 reserved,
-			       int *old_ref_mod, int *new_ref_mod);
+			       struct btrfs_ref *generic_ref, u64 reserved);
 int btrfs_add_delayed_extent_op(struct btrfs_fs_info *fs_info,
 				struct btrfs_trans_handle *trans,
 				u64 bytenr, u64 num_bytes,
--- a/fs/btrfs/extent-tree.c
+++ b/fs/btrfs/extent-tree.c
@@ -99,29 +99,6 @@ void btrfs_free_excluded_extents(struct
 			  start, end, EXTENT_UPTODATE);
 }

-static void add_pinned_bytes(struct btrfs_fs_info *fs_info,
-			     struct btrfs_ref *ref, int sign)
-{
-	struct btrfs_space_info *space_info;
-	s64 num_bytes;
-	u64 flags;
-
-	ASSERT(sign == 1 || sign == -1);
-	num_bytes = sign * ref->len;
-	if (ref->type == BTRFS_REF_METADATA) {
-		if (ref->tree_ref.root == BTRFS_CHUNK_TREE_OBJECTID)
-			flags = BTRFS_BLOCK_GROUP_SYSTEM;
-		else
-			flags = BTRFS_BLOCK_GROUP_METADATA;
-	} else {
-		flags = BTRFS_BLOCK_GROUP_DATA;
-	}
-
-	space_info = btrfs_find_space_info(fs_info, flags);
-	ASSERT(space_info);
-	percpu_counter_add_batch(&space_info->total_bytes_pinned, num_bytes,
-		    BTRFS_TOTAL_BYTES_PINNED_BATCH);
-}

 /* simple helper to search for an existing data extent at a given offset */
 int btrfs_lookup_data_extent(struct btrfs_fs_info *fs_info, u64 start, u64 len)
@@ -1535,7 +1512,6 @@ int btrfs_inc_extent_ref(struct btrfs_tr
 			 struct btrfs_ref *generic_ref)
 {
 	struct btrfs_fs_info *fs_info = root->fs_info;
-	int old_ref_mod, new_ref_mod;
 	int ret;

 	ASSERT(generic_ref->type != BTRFS_REF_NOT_SET &&
@@ -1545,13 +1521,9 @@ int btrfs_inc_extent_ref(struct btrfs_tr

 	if (generic_ref->type == BTRFS_REF_METADATA)
 		ret = btrfs_add_delayed_tree_ref(fs_info, trans, generic_ref,
-				NULL, &old_ref_mod, &new_ref_mod);
+				NULL);
 	else
-		ret = btrfs_add_delayed_data_ref(fs_info, trans, generic_ref, 0,
-						 &old_ref_mod, &new_ref_mod);
-
-	if (ret == 0 && old_ref_mod < 0 && new_ref_mod >= 0)
-		add_pinned_bytes(fs_info, generic_ref, -1);
+		ret = btrfs_add_delayed_data_ref(fs_info, trans, generic_ref, 0);

 	return ret;
 }
@@ -1932,20 +1904,9 @@ void btrfs_cleanup_ref_head_accounting(s
 	int nr_items = 1;	/* Dropping this ref head update. */

 	if (head->total_ref_mod < 0) {
-		struct btrfs_space_info *space_info;
-		u64 flags;
+		u64 flags = btrfs_ref_head_to_space_flags(head);

-		if (head->is_data)
-			flags = BTRFS_BLOCK_GROUP_DATA;
-		else if (head->is_system)
-			flags = BTRFS_BLOCK_GROUP_SYSTEM;
-		else
-			flags = BTRFS_BLOCK_GROUP_METADATA;
-		space_info = btrfs_find_space_info(fs_info, flags);
-		ASSERT(space_info);
-		percpu_counter_add_batch(&space_info->total_bytes_pinned,
-				   -head->num_bytes,
-				   BTRFS_TOTAL_BYTES_PINNED_BATCH);
+		btrfs_mod_total_bytes_pinned(fs_info, flags, -head->num_bytes);

 		/*
 		 * We had csum deletions accounted for in our delayed refs rsv,
@@ -2816,8 +2777,7 @@ static int pin_down_extent(struct btrfs_

 	trace_btrfs_space_reservation(fs_info, "pinned",
 				      cache->space_info->flags, num_bytes, 1);
-	percpu_counter_add_batch(&cache->space_info->total_bytes_pinned,
-		    num_bytes, BTRFS_TOTAL_BYTES_PINNED_BATCH);
+	__btrfs_mod_total_bytes_pinned(cache->space_info, num_bytes);
 	set_extent_dirty(fs_info->pinned_extents, bytenr,
 			 bytenr + num_bytes - 1, GFP_NOFS | __GFP_NOFAIL);
 	return 0;
@@ -3070,8 +3030,7 @@ static int unpin_extent_range(struct btr
 		cache->pinned -= len;
 		btrfs_space_info_update_bytes_pinned(fs_info, space_info, -len);
 		space_info->max_extent_size = 0;
-		percpu_counter_add_batch(&space_info->total_bytes_pinned,
-			    -len, BTRFS_TOTAL_BYTES_PINNED_BATCH);
+		__btrfs_mod_total_bytes_pinned(space_info, -len);
 		if (cache->ro) {
 			space_info->bytes_readonly += len;
 			readonly = true;
@@ -3503,7 +3462,6 @@ void btrfs_free_tree_block(struct btrfs_
 {
 	struct btrfs_fs_info *fs_info = root->fs_info;
 	struct btrfs_ref generic_ref = { 0 };
-	int pin = 1;
 	int ret;

 	btrfs_init_generic_ref(&generic_ref, BTRFS_DROP_DELAYED_REF,
@@ -3512,12 +3470,11 @@ void btrfs_free_tree_block(struct btrfs_
 			    root->root_key.objectid);

 	if (root->root_key.objectid != BTRFS_TREE_LOG_OBJECTID) {
-		int old_ref_mod, new_ref_mod;

-		ret = btrfs_add_delayed_tree_ref(fs_info, trans, &generic_ref, NULL,
- 						 &old_ref_mod, &new_ref_mod);
+		ret = btrfs_add_delayed_tree_ref(fs_info, trans, &generic_ref,
+						 NULL);
+
 		BUG_ON(ret); /* -ENOMEM */
-		pin = old_ref_mod >= 0 && new_ref_mod < 0;
 	}

 	if (last_ref && btrfs_header_generation(buf) == trans->transid) {
@@ -3529,7 +3486,6 @@ void btrfs_free_tree_block(struct btrfs_
 				goto out;
 		}

-		pin = 0;
 		cache = btrfs_lookup_block_group(fs_info, buf->start);

 		if (btrfs_header_flag(buf, BTRFS_HEADER_FLAG_WRITTEN)) {
@@ -3547,9 +3503,6 @@ void btrfs_free_tree_block(struct btrfs_
 		trace_btrfs_reserved_extent_free(fs_info, buf->start, buf->len);
 	}
 out:
-	if (pin)
-		add_pinned_bytes(fs_info, &generic_ref, 1);
-
 	if (last_ref) {
 		/*
 		 * Deleting the buffer, clear the corrupt flag since it doesn't
@@ -3565,7 +3518,6 @@ int btrfs_free_extent(struct btrfs_trans
 		      struct btrfs_ref *ref)
 {
 	struct btrfs_fs_info *fs_info = root->fs_info;
-	int old_ref_mod, new_ref_mod;
 	int ret;

 	if (btrfs_is_testing(fs_info))
@@ -3581,19 +3533,14 @@ int btrfs_free_extent(struct btrfs_trans
 	     ref->data_ref.ref_root == BTRFS_TREE_LOG_OBJECTID)) {
 		/* unlocks the pinned mutex */
 		btrfs_pin_extent(fs_info, ref->bytenr, ref->len, 1);
-		old_ref_mod = new_ref_mod = 0;
 		ret = 0;
 	} else if (ref->type == BTRFS_REF_METADATA) {
 		ret = btrfs_add_delayed_tree_ref(fs_info, trans, ref,
-						 NULL, &old_ref_mod, &new_ref_mod);
+						 NULL);
 	} else {
-		ret = btrfs_add_delayed_data_ref(fs_info, trans, ref, 0,
-						 &old_ref_mod, &new_ref_mod);
+		ret = btrfs_add_delayed_data_ref(fs_info, trans, ref, 0);
 	}

-	if (ret == 0 && old_ref_mod >= 0 && new_ref_mod < 0)
-		add_pinned_bytes(fs_info, ref, 1);
-
 	return ret;
 }

@@ -4451,16 +4398,15 @@ int btrfs_alloc_reserved_file_extent(str
 {
 	struct btrfs_fs_info *fs_info = root->fs_info;
 	struct btrfs_ref generic_ref = { 0 };
-	int ret;

 	BUG_ON(root->root_key.objectid == BTRFS_TREE_LOG_OBJECTID);

 	btrfs_init_generic_ref(&generic_ref, BTRFS_ADD_DELAYED_EXTENT,
 			       ins->objectid, ins->offset, 0);
 	btrfs_init_data_ref(&generic_ref, root->root_key.objectid, owner, offset);
-	ret = btrfs_add_delayed_data_ref(fs_info, trans, &generic_ref,
-					 ram_bytes, NULL, NULL);
-	return ret;
+
+	return  btrfs_add_delayed_data_ref(fs_info, trans, &generic_ref,
+					 ram_bytes);
 }

 /*
@@ -4623,7 +4569,7 @@ struct extent_buffer *btrfs_alloc_tree_b
 		generic_ref.real_root = root->root_key.objectid;
 		btrfs_init_tree_ref(&generic_ref, level, root_objectid);
 		ret = btrfs_add_delayed_tree_ref(fs_info, trans, &generic_ref,
-						 extent_op, NULL, NULL);
+						 extent_op);
 		if (ret)
 			goto out_free_delayed;
 	}
--- a/fs/btrfs/space-info.h
+++ b/fs/btrfs/space-info.h
@@ -153,4 +153,21 @@ static inline void btrfs_space_info_free
 int btrfs_reserve_data_bytes(struct btrfs_fs_info *fs_info, u64 bytes,
 			     enum btrfs_reserve_flush_enum flush);

+static inline void __btrfs_mod_total_bytes_pinned(
+					struct btrfs_space_info *space_info,
+					s64 mod)
+{
+	percpu_counter_add_batch(&space_info->total_bytes_pinned, mod,
+				 BTRFS_TOTAL_BYTES_PINNED_BATCH);
+}
+
+static inline void btrfs_mod_total_bytes_pinned(struct btrfs_fs_info *fs_info,
+						u64 flags, s64 mod)
+{
+	struct btrfs_space_info *space_info = btrfs_find_space_info(fs_info, flags);
+
+	ASSERT(space_info);
+	__btrfs_mod_total_bytes_pinned(space_info, mod);
+}
+
 #endif /* BTRFS_SPACE_INFO_H */
